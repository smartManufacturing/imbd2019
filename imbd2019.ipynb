{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwlAnC8mKKWt"
      },
      "source": [
        "修正Tersonflow與Keras版本"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oryu7yWhF3in",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41ae03ae-a5ab-4c5b-face-6a6078bd43a4"
      },
      "source": [
        "!pip uninstall keras\n",
        "!pip install tensorflow==2.2.0\n",
        "!pip install Keras==2.3.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: keras 2.9.0\n",
            "Uninstalling keras-2.9.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/keras-2.9.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/*\n",
            "Proceed (y/n)? ㄗ\n",
            "Your response ('ㄗ') was not one of the expected responses: y, n\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled keras-2.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.2.0\n",
            "  Downloading tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 4.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.50.0)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 37.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.19.6)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.3.0)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 31.9 MB/s \n",
            "\u001b[?25hCollecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.1 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.38.3)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
            "\u001b[K     |████████████████████████████████| 454 kB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "\u001b[K     |████████████████████████████████| 152 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.6)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n",
            "Installing collected packages: cachetools, google-auth, tensorflow-estimator, tensorboard, scipy, h5py, gast, tensorflow\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.2.0\n",
            "    Uninstalling cachetools-5.2.0:\n",
            "      Successfully uninstalled cachetools-5.2.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.14.1\n",
            "    Uninstalling google-auth-2.14.1:\n",
            "      Successfully uninstalled google-auth-2.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-vis 0.4.1 requires keras, which is not installed.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.23 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\u001b[0m\n",
            "Successfully installed cachetools-4.2.4 gast-0.3.3 google-auth-1.35.0 h5py-2.10.0 scipy-1.4.1 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Keras==2.3.1\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (1.4.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (1.1.2)\n",
            "Installing collected packages: keras-applications, Keras\n",
            "Successfully installed Keras-2.3.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baWEgaKBG4h3"
      },
      "source": [
        "匯入雲端硬碟"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VDsM0gWG8uQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b0f06f6-fc6b-4240-9c48-30de4408c896"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/My\\ Drive/Colab\\ Notebooks/imbd2019\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/imbd2019/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "config.ipynb  file.py\t  Mymodel.ipynb     preprocess.py  train\n",
            "config.py     main.ipynb  Mymodel.py\t    __pycache__\n",
            "file.ipynb    main.py\t  preprocess.ipynb  test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CxJ6ifbG-k7"
      },
      "source": [
        "載入配置"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3Q3J6j2HEHY"
      },
      "source": [
        "class _config:\n",
        "    # train 資料夾位置\n",
        "    #Train_Path = './train/'\n",
        "    Train_Path = '/content/drive/My Drive/Colab Notebooks/imbd2019/train/' \n",
        "    # test 資料夾位置\n",
        "    #Test_Path = './test/'\n",
        "    Test_Path = '/content/drive/My Drive/Colab Notebooks/imbd2019/test/'\n",
        "    # img size\n",
        "    imgrow = 164\n",
        "    imgcol = 4\n",
        "    # PTC 類別定義\n",
        "    PTC_class = {'G11': 0, 'G15': 1, 'G17': 2, 'G19': 3,\n",
        "                 'G32': 4, 'G34': 5, 'G48': 6, 'G49': 7}\n",
        "    test_y = {'1.txt': 'G11', '2.txt': 'G11',\n",
        "              '3.txt': 'G15', '4.txt': 'G15', '5.txt': 'G15', '6.txt': 'G15', '7.txt': 'G15', '8.txt': 'G15',\n",
        "              '9.txt': 'G17', '10.txt': 'G17',\n",
        "              '11.txt': 'G19', '12.txt': 'G19',\n",
        "              '13.txt': 'G32', '14.txt': 'G32', '15.txt': 'G32', '16.txt': 'G32', '17.txt': 'G32', '18.txt': 'G32',\n",
        "              '19.txt': 'G34', '20.txt': 'G34', '21.txt': 'G34', '22.txt': 'G34', '23.txt': 'G34', '24.txt': 'G34',\n",
        "              '25.txt': 'G48', '26.txt': 'G48', '27.txt': 'G48', '28.txt': 'G48', '29.txt': 'G48', '30.txt': 'G48',\n",
        "              '31.txt': 'G49', '32.txt': 'G49', '33.txt': 'G49', '34.txt': 'G49', '35.txt': 'G49', '36.txt': 'G49',\n",
        "              }\n",
        "    Batch_size = 32\n",
        "    epoch = 80\n",
        "    class_num = 8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Dfo0MCHN_R"
      },
      "source": [
        "載入檔案"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTIAW29pHfd8"
      },
      "source": [
        "import sys\n",
        "from os import walk\n",
        "import numpy as np\n",
        "import cv2\n",
        "#from config import _config\n",
        "\n",
        "class _file:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.Set = _config()\n",
        "        pass\n",
        "\n",
        "    def ReadData_TxT(self, Path):\n",
        "        AllPTCNp = np.zeros((1, self.Set.imgcol))\n",
        "        AllDataList = list()\n",
        "        labellsit = list()\n",
        "        PTClabelList = list()\n",
        "        namelist = list()\n",
        "        # 讀取資料夾內檔案\n",
        "        for root, dirs, file_all in walk(Path):\n",
        "\n",
        "            for _file in dirs:\n",
        "                # 讀取各類別資料夾(G11、G15、G17、G19、G32、G34、G48、G49)\n",
        "                for root, dirs, file_all in walk(Path+_file):\n",
        "                    # 讀取各類別資料夾內的TXT\n",
        "                    for name in file_all:\n",
        "                        # print(name)\n",
        "                        namelist.append(name)\n",
        "                        Datalist = list()\n",
        "                        SingleTxTNp = np.zeros((1, 4))\n",
        "                        PTCList = list()\n",
        "                        StartSaveData = False\n",
        "\n",
        "                        # 讀取TXT\n",
        "                        f = open(Path+_file+'/'+name, 'r', encoding='big5')\n",
        "                        data = f.readlines()\n",
        "                        for i in data:\n",
        "                            Datalist.append(i)\n",
        "                        f.close()\n",
        "\n",
        "                        # 讀取TXT內容後，淨化資料內容\n",
        "                        for i in Datalist:\n",
        "                            # 判斷此TXT類別\n",
        "                            if i.find('G') > -1:\n",
        "                                label = i[i.find('G'):i.find('-')]\n",
        "\n",
        "                                labellsit.append(label)\n",
        "                            # 經過Deg.F 確認開始讀取 PTC\n",
        "                            if StartSaveData:\n",
        "                                PTCList.append(i)\n",
        "\n",
        "                                # 若讀到換行符號，row方向往下堆疊\n",
        "                                if i.find('\\n') >= 0:\n",
        "                                    PTCList = PTCList[0].split('\\t')\n",
        "                                    showNp = np.array(PTCList)\n",
        "\n",
        "                                    PTCList = []\n",
        "                                    if showNp.shape[0] > 1:  # txt開頭有換行符號則須避開\n",
        "                                        SingleTxTNp = np.vstack(\n",
        "                                            (SingleTxTNp, showNp[0:self.Set.imgcol]))  # 資料往下堆疊\n",
        "                            if i.find('Deg.F') > -1:  # 經過Deg.F 確認開始讀取 PTC\n",
        "                                StartSaveData = True\n",
        "\n",
        "                        # 去除SingleTxTNp row=0資料，只留實際PTC資料\n",
        "                        SingleTxTNp = SingleTxTNp[1:self.Set.imgrow, :]\n",
        "                        SingleTxTNp_float = SingleTxTNp.astype(\n",
        "                            np.float)  # convert string array to float\n",
        "\n",
        "                        AllPTCNp = np.vstack(\n",
        "                            (AllPTCNp, SingleTxTNp_float))  # 讀完整個txt內容後存入結果\n",
        "                # 去除AllPTCNp row=0資料，只留實際PTC資料\n",
        "                ResultNp = AllPTCNp[1:AllPTCNp.shape[0], :].copy()\n",
        "\n",
        "        # 儲存Label資料\n",
        "        for i in labellsit:\n",
        "            i = i.strip(' ')\n",
        "            PTClabelList.append(self.Set.PTC_class[i])\n",
        "        PTClabelNp = np.array([PTClabelList])\n",
        "        PTClabelNp = PTClabelNp.T\n",
        "        print(ResultNp.shape)\n",
        "\n",
        "        return ResultNp, PTClabelNp, namelist\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPLkLMh5Hhpt"
      },
      "source": [
        "資料前處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJJzNc2iHqdj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class _preprocess:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def splitdata(self, dataNp, ratio, imgrow):\n",
        "        # input資料row維度\n",
        "        imgcounter = int(dataNp.shape[0]/imgrow)\n",
        "        # train維度=all*ratio\n",
        "        trainCounter = int(imgcounter*ratio)\n",
        "        trainNp = dataNp[0:trainCounter*imgrow, :]\n",
        "\n",
        "        # test=all-train\n",
        "        testNp = dataNp[trainCounter*imgrow:imgcounter*imgrow, :]\n",
        "\n",
        "        return trainNp, testNp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0MmsErwHtTf"
      },
      "source": [
        "訓練模型配置"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBBdoDHDHx9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee7249a-43d7-4f65-c441-54bd30dcbc4a"
      },
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Activation, Bidirectional\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Conv1D, MaxPooling1D, GlobalAveragePooling1D, MaxPool2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adadelta\n",
        "#from preprocess import _preprocess\n",
        "#from config import _config\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import pickle\n",
        "import gzip\n",
        "import urllib.request\n",
        "import json\n",
        "\n",
        "def plothistory(history):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# 繪製訓練 & 驗證的損失值\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class CNN_Model:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def Classification(self, x_train_all_Np, y_train_all_Np, x_testNp, y_testNp):\n",
        "        Set = _config()\n",
        "        process = _preprocess()\n",
        "\n",
        "        # train data分80%,test data分20%\n",
        "        train_x_np, val_x_np = process.splitdata(x_train_all_Np, 0.8, 1)\n",
        "        train_y_np, val_y_np = process.splitdata(y_train_all_Np, 0.8, 1)\n",
        "        print(train_x_np.shape, val_x_np.shape,\n",
        "              train_y_np.shape, val_y_np.shape)\n",
        "\n",
        "        # input image dimensions\n",
        "        img_rows, img_cols = Set.imgrow-1, Set.imgcol\n",
        "        train_x_np = train_x_np.reshape(\n",
        "            int(train_x_np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        val_x_np = val_x_np.reshape(\n",
        "            int(val_x_np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        x_train_all_Np = x_train_all_Np.reshape(\n",
        "            int(x_train_all_Np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        # print(x_train_all_Np.shape,x_testNp.shape)\n",
        "\n",
        "        _input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        # Normalize\n",
        "        x_mean = np.mean(x_train_all_Np, axis=0)\n",
        "        x_std = np.std(x_train_all_Np, axis=0)\n",
        "\n",
        "        train_x_np = (train_x_np-x_mean)/x_std\n",
        "        val_x_np = (val_x_np-x_mean)/x_std\n",
        "\n",
        "        print('x_train shape:', x_train_all_Np.shape)\n",
        "        print(train_x_np.shape, 'train samples')\n",
        "        print(val_x_np.shape, 'val samples')\n",
        "        print(train_y_np.shape, 'trainy samples')\n",
        "        print(val_y_np.shape, 'valy samples')\n",
        "        print(train_y_np)\n",
        "        train_y_np_Onehot = keras.utils.to_categorical(\n",
        "            train_y_np, Set.class_num)\n",
        "        val_y_np_Onehot = keras.utils.to_categorical(val_y_np, Set.class_num)\n",
        "        print('train_y_np_Onehot', train_y_np_Onehot.shape,\n",
        "              'val_y_np_Onehot', val_y_np_Onehot.shape)\n",
        "\n",
        "        print('_input_shape', _input_shape)\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(64, kernel_size=(1, 1),\n",
        "                         activation='relu',\n",
        "                         #  padding='SAME',\n",
        "                         input_shape=_input_shape))\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Conv2D(64, kernel_size=(1, 1), activation='relu'))\n",
        "        # # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "        # # model.add(Conv2D(64, kernel_size=(2, 2),activation='relu'))#\n",
        "\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        # model.add(MaxPooling2D(pool_size=(2, 2)))#\n",
        "\n",
        "        # model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "        # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        # model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dense(256, activation='relu'))\n",
        "        # model.add(Dense(512, activation='relu'))\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        # model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dense(2048, activation='relu'))\n",
        "        # model.add(Dense(2048, activation='relu'))\n",
        "        # model.add(Dense(2048, activation='relu'))\n",
        "        # model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(Set.class_num, activation='softmax'))\n",
        "\n",
        "        model.summary()\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        # model.fit(x_train_all_Np, y_train_all_Np_Onehot, validation_split=0.2, batch_size=32, epochs=50)\n",
        "        print('t', val_x_np.shape, val_y_np_Onehot.shape)\n",
        "\n",
        "        history = model.fit(train_x_np,\n",
        "                            train_y_np_Onehot,\n",
        "                            # validation_split=0.5,\n",
        "                            batch_size=Set.Batch_size,\n",
        "                            epochs=Set.epoch,\n",
        "                            # verbose=1)\n",
        "                            validation_data=(val_x_np, val_y_np_Onehot))\n",
        "        # score = model.evaluate(x_testNp, y_testNp_Onehot)\n",
        "        score = model.evaluate(val_x_np, val_y_np_Onehot, verbose=0)\n",
        "\n",
        "        x_testNp = x_testNp.reshape(\n",
        "            int(x_testNp.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        x_testNp = (x_testNp-x_mean)/x_std\n",
        "\n",
        "        predction = model.predict_classes(x_testNp)\n",
        "        # print(predction)\n",
        "        print('Test loss:', score[0])\n",
        "        print('Test accuracy:', score[1])\n",
        "        # plothistory(history)\n",
        "\n",
        "        return predction\n",
        "\n",
        "\n",
        "class LSTM_Model:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def Classification(self, x_train_all_Np, y_train_all_Np, x_testNp, y_testNp):\n",
        "        Set = _config()\n",
        "        process = _preprocess()\n",
        "        # learning_rate = 0.001\n",
        "        training_iters = Set.epoch\n",
        "        batch_size = Set.Batch_size\n",
        "        display_step = 10\n",
        "\n",
        "        n_input = Set.imgcol\n",
        "        n_step = Set.imgrow-1\n",
        "        n_hidden = 256\n",
        "        n_classes = Set.class_num\n",
        "\n",
        "        train_x_np, val_x_np = process.splitdata(x_train_all_Np, 0.8, 1)\n",
        "        train_y_np, val_y_np = process.splitdata(y_train_all_Np, 0.8, 1)\n",
        "\n",
        "        x_train_all_Np = x_train_all_Np.reshape(-1, n_step, n_input)\n",
        "        train_x_np = train_x_np.reshape(-1, n_step, n_input)\n",
        "        val_x_np = val_x_np.reshape(-1, n_step, n_input)\n",
        "\n",
        "        # train_x_np = train_x_np.astype('float32')\n",
        "        # val_x_np = val_x_np.astype('float32')\n",
        "\n",
        "        x_mean = np.mean(x_train_all_Np, axis=0)\n",
        "        x_std = np.std(x_train_all_Np, axis=0)\n",
        "\n",
        "        train_x_np = (train_x_np-x_mean)/x_std\n",
        "        val_x_np = (val_x_np-x_mean)/x_std\n",
        "\n",
        "        train_y_np_Onehot = keras.utils.to_categorical(train_y_np, n_classes)\n",
        "        val_y_np_Onehot = keras.utils.to_categorical(val_y_np, n_classes)\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(n_hidden, batch_input_shape=(\n",
        "            None, n_step, n_input), unroll=True))\n",
        "        # model.add(LSTM(n_hidden,unroll=True))\n",
        "        # model.add(LSTM(n_hidden))\n",
        "\n",
        "        # model.add(LSTM(n_hidden,batch_input_shape=(None, n_step, n_input),unroll=True))\n",
        "\n",
        "        # model.add(Bidirectional(LSTM(units=2,return_sequences=False)))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(n_classes))\n",
        "        model.add(Activation('softmax'))\n",
        "\n",
        "        adam = Adam(lr=0.001)\n",
        "        model.summary()\n",
        "        model.compile(optimizer=adam,\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.fit(train_x_np, train_y_np_Onehot,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=training_iters,\n",
        "                  verbose=1,\n",
        "                  validation_data=(val_x_np, val_y_np_Onehot))\n",
        "\n",
        "        scores = model.evaluate(val_x_np, val_y_np_Onehot, verbose=2)\n",
        "        print('LSTM test score:', scores[0])\n",
        "        print('LSTM test accuracy:', scores[1])\n",
        "\n",
        "        x_testNp = x_testNp.reshape(-1, n_step, n_input)\n",
        "        x_testNp = (x_testNp-x_mean)/x_std\n",
        "        predction = model.predict_classes(x_testNp)\n",
        "        print(predction)\n",
        "        return predction\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emh3ngEcH4ou"
      },
      "source": [
        "主程式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRYs1oheH-wm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7a23f2-2609-4d6c-d008-9331b1e4c817"
      },
      "source": [
        "#from file import _file\n",
        "#from config import _config\n",
        "#from Mymodel import CNN_Model, LSTM_Model\n",
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from tkinter import font\n",
        "import os\n",
        "\n",
        "def Project_Classification():\n",
        "    tXt = _file()\n",
        "    Set = _config()\n",
        "    # 讀取train data 及 test data\n",
        "    train_x, train_y, trainfilename = tXt.ReadData_TxT(Set.Train_Path)\n",
        "    test_x, test_y, testfilename = tXt.ReadData_TxT(Set.Test_Path)\n",
        "    print('=======', train_x.shape, train_y.shape)\n",
        "    # print(testfilename)\n",
        "    Real_y = list()\n",
        "    for i in testfilename:\n",
        "        _class = Set.test_y[i]\n",
        "        Real_y.append(Set.PTC_class[_class])\n",
        "    CNN = CNN_Model()\n",
        "    Predict_Y = CNN.Classification(train_x, train_y, test_x, test_y)\n",
        "    # goolgenet=goolgenet_Model()\n",
        "    # goolgenet.Classification(train_x,train_y,test_x,test_y)\n",
        "    # LSTM=LSTM_Model()\n",
        "    # Predict_Y=LSTM.Classification(train_x,train_y,test_x,test_y)\n",
        "\n",
        "    Real_yNp = np.array(Real_y)\n",
        "    print('predict:', Predict_Y)\n",
        "    print('Real:   ', Real_yNp)\n",
        "    Result = 0\n",
        "    for i in range(Real_yNp.shape[0]):\n",
        "        if(Predict_Y[i] == Real_yNp[i]):\n",
        "            Result = Result+1\n",
        "    Error = Result/Real_yNp.shape[0]\n",
        "    print('Accuracy(%):', Error*100)\n",
        "\n",
        "\n",
        "def main():\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # 使用 GPU 0\n",
        "    Project_Classification()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:67: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37490, 4)\n",
            "(3260, 4)\n",
            "======= (37490, 4) (230, 1)\n",
            "(29992, 4) (7498, 4) (184, 1) (46, 1)\n",
            "x_train shape: (230, 163, 4, 1)\n",
            "(184, 163, 4, 1) train samples\n",
            "(46, 163, 4, 1) val samples\n",
            "(184, 1) trainy samples\n",
            "(46, 1) valy samples\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]]\n",
            "train_y_np_Onehot (184, 8) val_y_np_Onehot (46, 8)\n",
            "_input_shape (163, 4, 1)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 163, 4, 64)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 81, 2, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 81, 2, 64)         4160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 40, 1, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               327808    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2048)              2099200   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 16392     \n",
            "=================================================================\n",
            "Total params: 3,137,608\n",
            "Trainable params: 3,137,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "t (46, 163, 4, 1) (46, 8)\n",
            "Train on 184 samples, validate on 46 samples\n",
            "Epoch 1/80\n",
            "184/184 [==============================] - 1s 5ms/step - loss: 1.7809 - accuracy: 0.3424 - val_loss: 3.3588 - val_accuracy: 0.3261\n",
            "Epoch 2/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.7589 - accuracy: 0.6196 - val_loss: 9.1748 - val_accuracy: 0.3261\n",
            "Epoch 3/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.6095 - accuracy: 0.6848 - val_loss: 7.3428 - val_accuracy: 0.3261\n",
            "Epoch 4/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.8207 - val_loss: 10.5080 - val_accuracy: 0.3261\n",
            "Epoch 5/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.3869 - accuracy: 0.8859 - val_loss: 13.5252 - val_accuracy: 0.3261\n",
            "Epoch 6/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.2312 - accuracy: 0.8913 - val_loss: 18.2359 - val_accuracy: 0.3261\n",
            "Epoch 7/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.2982 - accuracy: 0.9076 - val_loss: 18.9477 - val_accuracy: 0.3261\n",
            "Epoch 8/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8478 - val_loss: 9.7868 - val_accuracy: 0.3261\n",
            "Epoch 9/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.4173 - accuracy: 0.7935 - val_loss: 8.2205 - val_accuracy: 0.1522\n",
            "Epoch 10/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.3208 - accuracy: 0.8424 - val_loss: 10.8308 - val_accuracy: 0.3261\n",
            "Epoch 11/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.2356 - accuracy: 0.8859 - val_loss: 13.0616 - val_accuracy: 0.3261\n",
            "Epoch 12/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.2323 - accuracy: 0.8696 - val_loss: 13.3233 - val_accuracy: 0.3261\n",
            "Epoch 13/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1459 - accuracy: 0.9293 - val_loss: 14.3962 - val_accuracy: 0.3261\n",
            "Epoch 14/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1365 - accuracy: 0.9402 - val_loss: 14.6520 - val_accuracy: 0.3261\n",
            "Epoch 15/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1360 - accuracy: 0.9402 - val_loss: 13.9854 - val_accuracy: 0.3261\n",
            "Epoch 16/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.2063 - accuracy: 0.9293 - val_loss: 14.6090 - val_accuracy: 0.3261\n",
            "Epoch 17/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1436 - accuracy: 0.9457 - val_loss: 15.7413 - val_accuracy: 0.3261\n",
            "Epoch 18/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1780 - accuracy: 0.9185 - val_loss: 16.0823 - val_accuracy: 0.3261\n",
            "Epoch 19/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9511 - val_loss: 14.2636 - val_accuracy: 0.3261\n",
            "Epoch 20/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0843 - accuracy: 0.9728 - val_loss: 13.9540 - val_accuracy: 0.3261\n",
            "Epoch 21/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1062 - accuracy: 0.9620 - val_loss: 14.1749 - val_accuracy: 0.3261\n",
            "Epoch 22/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1256 - accuracy: 0.9511 - val_loss: 14.8707 - val_accuracy: 0.3261\n",
            "Epoch 23/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9674 - val_loss: 13.8671 - val_accuracy: 0.3261\n",
            "Epoch 24/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0513 - accuracy: 0.9837 - val_loss: 13.4167 - val_accuracy: 0.3261\n",
            "Epoch 25/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9946 - val_loss: 13.5603 - val_accuracy: 0.3261\n",
            "Epoch 26/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9891 - val_loss: 13.9213 - val_accuracy: 0.3261\n",
            "Epoch 27/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1407 - accuracy: 0.9457 - val_loss: 14.2340 - val_accuracy: 0.3261\n",
            "Epoch 28/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1657 - accuracy: 0.9457 - val_loss: 14.2872 - val_accuracy: 0.3261\n",
            "Epoch 29/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1217 - accuracy: 0.9402 - val_loss: 15.0766 - val_accuracy: 0.3261\n",
            "Epoch 30/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1195 - accuracy: 0.9565 - val_loss: 15.0924 - val_accuracy: 0.3261\n",
            "Epoch 31/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9565 - val_loss: 15.7552 - val_accuracy: 0.3261\n",
            "Epoch 32/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0761 - accuracy: 0.9620 - val_loss: 16.6180 - val_accuracy: 0.3261\n",
            "Epoch 33/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0550 - accuracy: 0.9783 - val_loss: 17.5506 - val_accuracy: 0.3261\n",
            "Epoch 34/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9891 - val_loss: 18.2501 - val_accuracy: 0.3261\n",
            "Epoch 35/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0235 - accuracy: 0.9891 - val_loss: 18.9769 - val_accuracy: 0.3261\n",
            "Epoch 36/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 19.1850 - val_accuracy: 0.3261\n",
            "Epoch 37/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1294 - accuracy: 0.9674 - val_loss: 19.8274 - val_accuracy: 0.3261\n",
            "Epoch 38/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9728 - val_loss: 18.5187 - val_accuracy: 0.3261\n",
            "Epoch 39/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1075 - accuracy: 0.9565 - val_loss: 17.9164 - val_accuracy: 0.3261\n",
            "Epoch 40/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0609 - accuracy: 0.9728 - val_loss: 17.1420 - val_accuracy: 0.3261\n",
            "Epoch 41/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0481 - accuracy: 0.9783 - val_loss: 17.1671 - val_accuracy: 0.3261\n",
            "Epoch 42/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9783 - val_loss: 18.7961 - val_accuracy: 0.3261\n",
            "Epoch 43/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0253 - accuracy: 0.9946 - val_loss: 20.0689 - val_accuracy: 0.3261\n",
            "Epoch 44/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0195 - accuracy: 0.9891 - val_loss: 20.8159 - val_accuracy: 0.3261\n",
            "Epoch 45/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 21.3334 - val_accuracy: 0.3261\n",
            "Epoch 46/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 21.5914 - val_accuracy: 0.3261\n",
            "Epoch 47/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 22.2261 - val_accuracy: 0.3261\n",
            "Epoch 48/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 22.3552 - val_accuracy: 0.3261\n",
            "Epoch 49/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0881 - accuracy: 0.9783 - val_loss: 22.4425 - val_accuracy: 0.3261\n",
            "Epoch 50/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9674 - val_loss: 23.2335 - val_accuracy: 0.3261\n",
            "Epoch 51/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9837 - val_loss: 22.9409 - val_accuracy: 0.3261\n",
            "Epoch 52/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9837 - val_loss: 21.9960 - val_accuracy: 0.3261\n",
            "Epoch 53/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0393 - accuracy: 0.9891 - val_loss: 21.6734 - val_accuracy: 0.3261\n",
            "Epoch 54/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0454 - accuracy: 0.9783 - val_loss: 22.5035 - val_accuracy: 0.3261\n",
            "Epoch 55/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0558 - accuracy: 0.9728 - val_loss: 19.8652 - val_accuracy: 0.3261\n",
            "Epoch 56/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.6420 - accuracy: 0.9348 - val_loss: 13.8729 - val_accuracy: 0.3261\n",
            "Epoch 57/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.3030 - accuracy: 0.9511 - val_loss: 4.8631 - val_accuracy: 0.3261\n",
            "Epoch 58/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.2947 - accuracy: 0.9130 - val_loss: 5.8243 - val_accuracy: 0.3261\n",
            "Epoch 59/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1593 - accuracy: 0.9293 - val_loss: 5.3046 - val_accuracy: 0.3261\n",
            "Epoch 60/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1209 - accuracy: 0.9620 - val_loss: 6.6087 - val_accuracy: 0.3261\n",
            "Epoch 61/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9728 - val_loss: 6.9320 - val_accuracy: 0.3261\n",
            "Epoch 62/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1723 - accuracy: 0.9402 - val_loss: 8.5818 - val_accuracy: 0.3261\n",
            "Epoch 63/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9728 - val_loss: 8.2765 - val_accuracy: 0.3261\n",
            "Epoch 64/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0613 - accuracy: 0.9783 - val_loss: 5.8874 - val_accuracy: 0.3261\n",
            "Epoch 65/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0470 - accuracy: 0.9891 - val_loss: 6.7185 - val_accuracy: 0.3261\n",
            "Epoch 66/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9891 - val_loss: 7.7838 - val_accuracy: 0.3261\n",
            "Epoch 67/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 7.6873 - val_accuracy: 0.3261\n",
            "Epoch 68/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 7.6909 - val_accuracy: 0.3261\n",
            "Epoch 69/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 7.8206 - val_accuracy: 0.3261\n",
            "Epoch 70/80\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 7.9506 - val_accuracy: 0.3261\n",
            "Epoch 71/80\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 8.0449 - val_accuracy: 0.3261\n",
            "Epoch 72/80\n",
            "184/184 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 8.0879 - val_accuracy: 0.3261\n",
            "Epoch 73/80\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 0.0553 - accuracy: 0.9837 - val_loss: 8.1088 - val_accuracy: 0.3261\n",
            "Epoch 74/80\n",
            "184/184 [==============================] - 1s 5ms/step - loss: 0.2944 - accuracy: 0.9674 - val_loss: 8.1023 - val_accuracy: 0.3261\n",
            "Epoch 75/80\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 0.0941 - accuracy: 0.9783 - val_loss: 8.0291 - val_accuracy: 0.3261\n",
            "Epoch 76/80\n",
            "184/184 [==============================] - 1s 5ms/step - loss: 0.0880 - accuracy: 0.9620 - val_loss: 8.1207 - val_accuracy: 0.3261\n",
            "Epoch 77/80\n",
            "184/184 [==============================] - 1s 5ms/step - loss: 0.0682 - accuracy: 0.9783 - val_loss: 8.4129 - val_accuracy: 0.3261\n",
            "Epoch 78/80\n",
            "184/184 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 8.6073 - val_accuracy: 0.3261\n",
            "Epoch 79/80\n",
            "184/184 [==============================] - 1s 5ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 8.6879 - val_accuracy: 0.3261\n",
            "Epoch 80/80\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9837 - val_loss: 8.6586 - val_accuracy: 0.3261\n",
            "Test loss: 8.658568921296492\n",
            "Test accuracy: 0.32608696818351746\n",
            "predict: [3 3 0 4 5 5 5 2 2 5 5 5 5 4 4 4 4 2 0 0]\n",
            "Real:    [3 3 4 4 5 5 5 6 6 6 5 5 5 4 4 4 4 2 0 0]\n",
            "Accuracy(%): 80.0\n"
          ]
        }
      ]
    }
  ]
}
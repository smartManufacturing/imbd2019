{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwlAnC8mKKWt"
      },
      "source": [
        "修正Tersonflow與Keras版本"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oryu7yWhF3in",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e850074d-d77c-4091-eba0-fe88842582d4"
      },
      "source": [
        "!pip uninstall keras\n",
        "!pip install tensorflow==2.2.0\n",
        "!pip install Keras==2.3.1\n",
        "#!pip uninstall keras\n",
        "#!pip install tensorflow --upgrade\n",
        "#!pip install keras --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: Keras 2.2.0\n",
            "Uninstalling Keras-2.2.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/Keras-2.2.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/docs/*\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/docs/md_autogen.py\n",
            "    /usr/local/lib/python3.7/dist-packages/docs/update_docs.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled Keras-2.2.0\n",
            "Requirement already satisfied: tensorflow==2.2.0 in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.39.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.17.3)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Collecting keras-preprocessing>=1.1.0\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.12.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.10.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.34.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.5)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n",
            "Installing collected packages: keras-preprocessing\n",
            "  Attempting uninstall: keras-preprocessing\n",
            "    Found existing installation: Keras-Preprocessing 1.0.1\n",
            "    Uninstalling Keras-Preprocessing-1.0.1:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.1\n",
            "Successfully installed keras-preprocessing-1.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras_preprocessing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting Keras==2.3.1\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 377 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (3.13)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30 kB 43.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40 kB 49.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1) (1.19.5)\n",
            "Installing collected packages: keras-applications, Keras\n",
            "  Attempting uninstall: keras-applications\n",
            "    Found existing installation: Keras-Applications 1.0.2\n",
            "    Uninstalling Keras-Applications-1.0.2:\n",
            "      Successfully uninstalled Keras-Applications-1.0.2\n",
            "Successfully installed Keras-2.3.1 keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "keras_applications"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baWEgaKBG4h3"
      },
      "source": [
        "匯入雲端硬碟"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VDsM0gWG8uQ",
        "outputId": "400ec37e-492e-463d-9692-59019907cfe9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/My\\ Drive/Colab\\ Notebooks/imbd2019\n",
        "import sys\n",
        "sys.path.append('content/drive/My Drive/Colab Notebooks/imbd2019/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "config.ipynb  file.py\t  Mymodel.ipynb     preprocess.py  train\n",
            "config.py     main.ipynb  Mymodel.py\t    __pycache__\n",
            "file.ipynb    main.py\t  preprocess.ipynb  test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CxJ6ifbG-k7"
      },
      "source": [
        "載入配置"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLABH9QjXvIi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3Q3J6j2HEHY"
      },
      "source": [
        "class _config:\n",
        "    # train 資料夾位置\n",
        "    #Train_Path = './train/'\n",
        "    Train_Path = '/content/drive/My Drive/Colab Notebooks/imbd2019/train/' \n",
        "    # test 資料夾位置\n",
        "    #Test_Path = './test/'\n",
        "    Test_Path = '/content/drive/My Drive/Colab Notebooks/imbd2019/test/'\n",
        "    # img size\n",
        "    imgrow = 164\n",
        "    imgcol = 4\n",
        "    # PTC 類別定義\n",
        "    PTC_class = {'G11': 0, 'G15': 1, 'G17': 2, 'G19': 3,\n",
        "                 'G32': 4, 'G34': 5, 'G48': 6, 'G49': 7}\n",
        "    test_y = {'1.txt': 'G11', '2.txt': 'G11',\n",
        "              '3.txt': 'G15', '4.txt': 'G15', '5.txt': 'G15', '6.txt': 'G15', '7.txt': 'G15', '8.txt': 'G15',\n",
        "              '9.txt': 'G17', '10.txt': 'G17',\n",
        "              '11.txt': 'G19', '12.txt': 'G19',\n",
        "              '13.txt': 'G32', '14.txt': 'G32', '15.txt': 'G32', '16.txt': 'G32', '17.txt': 'G32', '18.txt': 'G32',\n",
        "              '19.txt': 'G34', '20.txt': 'G34', '21.txt': 'G34', '22.txt': 'G34', '23.txt': 'G34', '24.txt': 'G34',\n",
        "              '25.txt': 'G48', '26.txt': 'G48', '27.txt': 'G48', '28.txt': 'G48', '29.txt': 'G48', '30.txt': 'G48',\n",
        "              '31.txt': 'G49', '32.txt': 'G49', '33.txt': 'G49', '34.txt': 'G49', '35.txt': 'G49', '36.txt': 'G49',\n",
        "              }\n",
        "    Batch_size = 32\n",
        "    epoch = 70\n",
        "    class_num = 8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Dfo0MCHN_R"
      },
      "source": [
        "載入檔案"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTIAW29pHfd8"
      },
      "source": [
        "import sys\n",
        "from os import walk\n",
        "import numpy as np\n",
        "import cv2\n",
        "#from config import _config\n",
        "\n",
        "\n",
        "class _file:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.Set = _config()\n",
        "        pass\n",
        "\n",
        "    def ReadData_TxT(self, Path):\n",
        "        AllPTCNp = np.zeros((1, self.Set.imgcol))\n",
        "        AllDataList = list()\n",
        "        labellsit = list()\n",
        "        PTClabelList = list()\n",
        "        namelist = list()\n",
        "        # 讀取資料夾內檔案\n",
        "        for root, dirs, file_all in walk(Path):\n",
        "\n",
        "            for _file in dirs:\n",
        "                # 讀取各類別資料夾(G11、G15、G17、G19、G32、G34、G48、G49)\n",
        "                for root, dirs, file_all in walk(Path+_file):\n",
        "                    # 讀取各類別資料夾內的TXT\n",
        "                    for name in file_all:\n",
        "                        # print(name)\n",
        "                        namelist.append(name)\n",
        "                        Datalist = list()\n",
        "                        SingleTxTNp = np.zeros((1, 4))\n",
        "                        PTCList = list()\n",
        "                        StartSaveData = False\n",
        "\n",
        "                        # 讀取TXT\n",
        "                        f = open(Path+_file+'/'+name, 'r', encoding='big5')\n",
        "                        data = f.readlines()\n",
        "                        for i in data:\n",
        "                            Datalist.append(i)\n",
        "                        f.close()\n",
        "\n",
        "                        # 讀取TXT內容後，淨化資料內容\n",
        "                        for i in Datalist:\n",
        "                            # 判斷此TXT類別\n",
        "                            if i.find('G') > -1:\n",
        "                                label = i[i.find('G'):i.find('-')]\n",
        "\n",
        "                                labellsit.append(label)\n",
        "                            # 經過Deg.F 確認開始讀取 PTC\n",
        "                            if StartSaveData:\n",
        "                                PTCList.append(i)\n",
        "\n",
        "                                # 若讀到換行符號，row方向往下堆疊\n",
        "                                if i.find('\\n') >= 0:\n",
        "                                    PTCList = PTCList[0].split('\\t')\n",
        "                                    showNp = np.array(PTCList)\n",
        "\n",
        "                                    PTCList = []\n",
        "                                    if showNp.shape[0] > 1:  # txt開頭有換行符號則須避開\n",
        "                                        SingleTxTNp = np.vstack(\n",
        "                                            (SingleTxTNp, showNp[0:self.Set.imgcol]))  # 資料往下堆疊\n",
        "                            if i.find('Deg.F') > -1:  # 經過Deg.F 確認開始讀取 PTC\n",
        "                                StartSaveData = True\n",
        "\n",
        "                        # 去除SingleTxTNp row=0資料，只留實際PTC資料\n",
        "                        SingleTxTNp = SingleTxTNp[1:self.Set.imgrow, :]\n",
        "                        SingleTxTNp_float = SingleTxTNp.astype(\n",
        "                            np.float)  # convert string array to float\n",
        "\n",
        "                        AllPTCNp = np.vstack(\n",
        "                            (AllPTCNp, SingleTxTNp_float))  # 讀完整個txt內容後存入結果\n",
        "                # 去除AllPTCNp row=0資料，只留實際PTC資料\n",
        "                ResultNp = AllPTCNp[1:AllPTCNp.shape[0], :].copy()\n",
        "\n",
        "        # 儲存Label資料\n",
        "        for i in labellsit:\n",
        "            i = i.strip(' ')\n",
        "            PTClabelList.append(self.Set.PTC_class[i])\n",
        "        PTClabelNp = np.array([PTClabelList])\n",
        "        PTClabelNp = PTClabelNp.T\n",
        "        print(ResultNp.shape)\n",
        "\n",
        "        return ResultNp, PTClabelNp, namelist\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPLkLMh5Hhpt"
      },
      "source": [
        "資料前處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJJzNc2iHqdj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class _preprocess:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def splitdata(self, dataNp, ratio, imgrow):\n",
        "        # input資料row維度\n",
        "        imgcounter = int(dataNp.shape[0]/imgrow)\n",
        "        # train維度=all*ratio\n",
        "        trainCounter = int(imgcounter*ratio)\n",
        "        trainNp = dataNp[0:trainCounter*imgrow, :]\n",
        "\n",
        "        # test=all-train\n",
        "        testNp = dataNp[trainCounter*imgrow:imgcounter*imgrow, :]\n",
        "\n",
        "        return trainNp, testNp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0MmsErwHtTf"
      },
      "source": [
        "訓練模型配置"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBBdoDHDHx9_"
      },
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Activation, Bidirectional\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import LSTM\n",
        "\n",
        "#import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Conv1D, MaxPooling1D, GlobalAveragePooling1D, MaxPool2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adadelta\n",
        "#from preprocess import _preprocess\n",
        "#from config import _config\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import pickle\n",
        "import gzip\n",
        "import urllib.request\n",
        "import json\n",
        "\n",
        "\n",
        "def plothistory(history):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# 繪製訓練 & 驗證的損失值\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class CNN_Model:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def Classification(self, x_train_all_Np, y_train_all_Np, x_testNp, y_testNp):\n",
        "        Set = _config()\n",
        "        process = _preprocess()\n",
        "\n",
        "        # train data分80%,test data分20%\n",
        "        train_x_np, val_x_np = process.splitdata(x_train_all_Np, 0.8, 1)\n",
        "        train_y_np, val_y_np = process.splitdata(y_train_all_Np, 0.8, 1)\n",
        "        print(train_x_np.shape, val_x_np.shape,\n",
        "              train_y_np.shape, val_y_np.shape)\n",
        "\n",
        "        # input image dimensions\n",
        "        img_rows, img_cols = Set.imgrow-1, Set.imgcol\n",
        "        train_x_np = train_x_np.reshape(\n",
        "            int(train_x_np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        val_x_np = val_x_np.reshape(\n",
        "            int(val_x_np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        x_train_all_Np = x_train_all_Np.reshape(\n",
        "            int(x_train_all_Np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        # print(x_train_all_Np.shape,x_testNp.shape)\n",
        "\n",
        "        _input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        # Normalize\n",
        "        x_mean = np.mean(x_train_all_Np, axis=0)\n",
        "        x_std = np.std(x_train_all_Np, axis=0)\n",
        "\n",
        "        train_x_np = (train_x_np-x_mean)/x_std\n",
        "        val_x_np = (val_x_np-x_mean)/x_std\n",
        "\n",
        "        print('x_train shape:', x_train_all_Np.shape)\n",
        "        print(train_x_np.shape, 'train samples')\n",
        "        print(val_x_np.shape, 'val samples')\n",
        "        print(train_y_np.shape, 'trainy samples')\n",
        "        print(val_y_np.shape, 'valy samples')\n",
        "        print(train_y_np)\n",
        "        train_y_np_Onehot = keras.utils.to_categorical(\n",
        "            train_y_np, Set.class_num)\n",
        "        val_y_np_Onehot = keras.utils.to_categorical(val_y_np, Set.class_num)\n",
        "        print('train_y_np_Onehot', train_y_np_Onehot.shape,\n",
        "              'val_y_np_Onehot', val_y_np_Onehot.shape)\n",
        "\n",
        "        print('_input_shape', _input_shape)\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(64, kernel_size=(1, 1),\n",
        "                         activation='relu',\n",
        "                         #  padding='SAME',\n",
        "                         input_shape=_input_shape))\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Conv2D(64, kernel_size=(1, 1), activation='relu'))\n",
        "        # # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "        # # model.add(Conv2D(64, kernel_size=(2, 2),activation='relu'))#\n",
        "\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        # model.add(MaxPooling2D(pool_size=(2, 2)))#\n",
        "\n",
        "        # model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "        # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        # model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dense(256, activation='relu'))\n",
        "        # model.add(Dense(512, activation='relu'))\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        # model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dense(2048, activation='relu'))\n",
        "        # model.add(Dense(2048, activation='relu'))\n",
        "        # model.add(Dense(2048, activation='relu'))\n",
        "        # model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(Set.class_num, activation='softmax'))\n",
        "\n",
        "        model.summary()\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        # model.fit(x_train_all_Np, y_train_all_Np_Onehot, validation_split=0.2, batch_size=32, epochs=50)\n",
        "        print('t', val_x_np.shape, val_y_np_Onehot.shape)\n",
        "\n",
        "        history = model.fit(train_x_np,\n",
        "                            train_y_np_Onehot,\n",
        "                            # validation_split=0.5,\n",
        "                            batch_size=Set.Batch_size,\n",
        "                            epochs=Set.epoch,\n",
        "                            # verbose=1)\n",
        "                            validation_data=(val_x_np, val_y_np_Onehot))\n",
        "        # score = model.evaluate(x_testNp, y_testNp_Onehot)\n",
        "        score = model.evaluate(val_x_np, val_y_np_Onehot, verbose=0)\n",
        "\n",
        "        x_testNp = x_testNp.reshape(\n",
        "            int(x_testNp.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        x_testNp = (x_testNp-x_mean)/x_std\n",
        "\n",
        "        predction = model.predict_classes(x_testNp)\n",
        "        # print(predction)\n",
        "        print('Test loss:', score[0])\n",
        "        print('Test accuracy:', score[1])\n",
        "        # plothistory(history)\n",
        "\n",
        "        return predction\n",
        "\n",
        "\n",
        "class LSTM_Model:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def Classification(self, x_train_all_Np, y_train_all_Np, x_testNp, y_testNp):\n",
        "        Set = _config()\n",
        "        process = _preprocess()\n",
        "        # learning_rate = 0.001\n",
        "        training_iters = Set.epoch\n",
        "        batch_size = Set.Batch_size\n",
        "        display_step = 10\n",
        "\n",
        "        n_input = Set.imgcol\n",
        "        n_step = Set.imgrow-1\n",
        "        n_hidden = 256\n",
        "        n_classes = Set.class_num\n",
        "\n",
        "        train_x_np, val_x_np = process.splitdata(x_train_all_Np, 0.8, 1)\n",
        "        train_y_np, val_y_np = process.splitdata(y_train_all_Np, 0.8, 1)\n",
        "\n",
        "        x_train_all_Np = x_train_all_Np.reshape(-1, n_step, n_input)\n",
        "        train_x_np = train_x_np.reshape(-1, n_step, n_input)\n",
        "        val_x_np = val_x_np.reshape(-1, n_step, n_input)\n",
        "\n",
        "        # train_x_np = train_x_np.astype('float32')\n",
        "        # val_x_np = val_x_np.astype('float32')\n",
        "\n",
        "        x_mean = np.mean(x_train_all_Np, axis=0)\n",
        "        x_std = np.std(x_train_all_Np, axis=0)\n",
        "\n",
        "        train_x_np = (train_x_np-x_mean)/x_std\n",
        "        val_x_np = (val_x_np-x_mean)/x_std\n",
        "\n",
        "        train_y_np_Onehot = keras.utils.to_categorical(train_y_np, n_classes)\n",
        "        val_y_np_Onehot = keras.utils.to_categorical(val_y_np, n_classes)\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(n_hidden, batch_input_shape=(\n",
        "            None, n_step, n_input), unroll=True))\n",
        "        # model.add(LSTM(n_hidden,unroll=True))\n",
        "        # model.add(LSTM(n_hidden))\n",
        "\n",
        "        # model.add(LSTM(n_hidden,batch_input_shape=(None, n_step, n_input),unroll=True))\n",
        "\n",
        "        # model.add(Bidirectional(LSTM(units=2,return_sequences=False)))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(n_classes))\n",
        "        model.add(Activation('softmax'))\n",
        "\n",
        "        adam = Adam(lr=0.001)\n",
        "        model.summary()\n",
        "        model.compile(optimizer=adam,\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.fit(train_x_np, train_y_np_Onehot,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=training_iters,\n",
        "                  verbose=1,\n",
        "                  validation_data=(val_x_np, val_y_np_Onehot))\n",
        "\n",
        "        scores = model.evaluate(val_x_np, val_y_np_Onehot, verbose=2)\n",
        "        print('LSTM test score:', scores[0])\n",
        "        print('LSTM test accuracy:', scores[1])\n",
        "\n",
        "        x_testNp = x_testNp.reshape(-1, n_step, n_input)\n",
        "        x_testNp = (x_testNp-x_mean)/x_std\n",
        "        predction = model.predict_classes(x_testNp)\n",
        "        print(predction)\n",
        "        return predction\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emh3ngEcH4ou"
      },
      "source": [
        "主程式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRYs1oheH-wm",
        "outputId": "c26ffe3c-ede5-4cc7-c6fe-6c056dce49b3"
      },
      "source": [
        "#from file import _file\n",
        "#from config import _config\n",
        "#from Mymodel import CNN_Model, LSTM_Model\n",
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from tkinter import font\n",
        "import os\n",
        "\n",
        "\n",
        "def Project_Classification():\n",
        "    tXt = _file()\n",
        "    Set = _config()\n",
        "    # 讀取train data 及 test data\n",
        "    train_x, train_y, trainfilename = tXt.ReadData_TxT(Set.Train_Path)\n",
        "    test_x, test_y, testfilename = tXt.ReadData_TxT(Set.Test_Path)\n",
        "    print('=======', train_x.shape, train_y.shape)\n",
        "    # print(testfilename)\n",
        "    Real_y = list()\n",
        "    for i in testfilename:\n",
        "        _class = Set.test_y[i]\n",
        "        Real_y.append(Set.PTC_class[_class])\n",
        "    CNN = CNN_Model()\n",
        "    Predict_Y = CNN.Classification(train_x, train_y, test_x, test_y)\n",
        "    # goolgenet=goolgenet_Model()\n",
        "    # goolgenet.Classification(train_x,train_y,test_x,test_y)\n",
        "    # LSTM=LSTM_Model()\n",
        "    # Predict_Y=LSTM.Classification(train_x,train_y,test_x,test_y)\n",
        "\n",
        "    Real_yNp = np.array(Real_y)\n",
        "    print('predict:', Predict_Y)\n",
        "    print('Real:   ', Real_yNp)\n",
        "    Result = 0\n",
        "    for i in range(Real_yNp.shape[0]):\n",
        "        if(Predict_Y[i] == Real_yNp[i]):\n",
        "            Result = Result+1\n",
        "    Error = Result/Real_yNp.shape[0]\n",
        "    print('Accuracy(%):', Error*100)\n",
        "\n",
        "\n",
        "def main():\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # 使用 GPU 0\n",
        "    Project_Classification()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37490, 4)\n",
            "(3260, 4)\n",
            "======= (37490, 4) (230, 1)\n",
            "(29992, 4) (7498, 4) (184, 1) (46, 1)\n",
            "x_train shape: (230, 163, 4, 1)\n",
            "(184, 163, 4, 1) train samples\n",
            "(46, 163, 4, 1) val samples\n",
            "(184, 1) trainy samples\n",
            "(46, 1) valy samples\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [7]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]]\n",
            "train_y_np_Onehot (184, 8) val_y_np_Onehot (46, 8)\n",
            "_input_shape (163, 4, 1)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 163, 4, 64)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 81, 2, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 81, 2, 64)         4160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 40, 1, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               327808    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2048)              2099200   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 16392     \n",
            "=================================================================\n",
            "Total params: 3,137,608\n",
            "Trainable params: 3,137,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "t (46, 163, 4, 1) (46, 8)\n",
            "Train on 184 samples, validate on 46 samples\n",
            "Epoch 1/70\n",
            "184/184 [==============================] - 1s 4ms/step - loss: 1.8089 - accuracy: 0.2446 - val_loss: 2.5423 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.7941 - accuracy: 0.6250 - val_loss: 5.9076 - val_accuracy: 0.3261\n",
            "Epoch 3/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.5404 - accuracy: 0.7065 - val_loss: 11.2509 - val_accuracy: 0.3261\n",
            "Epoch 4/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.7554 - val_loss: 8.4543 - val_accuracy: 0.3261\n",
            "Epoch 5/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.4054 - accuracy: 0.8315 - val_loss: 8.2124 - val_accuracy: 0.3261\n",
            "Epoch 6/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.3032 - accuracy: 0.8696 - val_loss: 11.7500 - val_accuracy: 0.3261\n",
            "Epoch 7/70\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.2404 - accuracy: 0.8967 - val_loss: 15.4119 - val_accuracy: 0.3261\n",
            "Epoch 8/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.2197 - accuracy: 0.9130 - val_loss: 17.3469 - val_accuracy: 0.3261\n",
            "Epoch 9/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.2065 - accuracy: 0.9076 - val_loss: 16.7561 - val_accuracy: 0.3261\n",
            "Epoch 10/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1798 - accuracy: 0.9293 - val_loss: 18.1163 - val_accuracy: 0.3261\n",
            "Epoch 11/70\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9076 - val_loss: 15.5003 - val_accuracy: 0.1957\n",
            "Epoch 12/70\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.9076 - val_loss: 10.5851 - val_accuracy: 0.3261\n",
            "Epoch 13/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.2153 - accuracy: 0.8913 - val_loss: 6.5430 - val_accuracy: 0.3261\n",
            "Epoch 14/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1627 - accuracy: 0.9293 - val_loss: 6.2877 - val_accuracy: 0.3261\n",
            "Epoch 15/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1346 - accuracy: 0.9239 - val_loss: 7.5749 - val_accuracy: 0.3261\n",
            "Epoch 16/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1332 - accuracy: 0.9457 - val_loss: 8.0613 - val_accuracy: 0.3261\n",
            "Epoch 17/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1094 - accuracy: 0.9457 - val_loss: 8.1922 - val_accuracy: 0.3261\n",
            "Epoch 18/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1110 - accuracy: 0.9457 - val_loss: 8.4112 - val_accuracy: 0.3261\n",
            "Epoch 19/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1447 - accuracy: 0.9293 - val_loss: 8.9111 - val_accuracy: 0.3261\n",
            "Epoch 20/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1221 - accuracy: 0.9565 - val_loss: 9.2513 - val_accuracy: 0.3261\n",
            "Epoch 21/70\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9674 - val_loss: 9.6732 - val_accuracy: 0.3261\n",
            "Epoch 22/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1091 - accuracy: 0.9348 - val_loss: 10.0214 - val_accuracy: 0.3261\n",
            "Epoch 23/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1526 - accuracy: 0.9402 - val_loss: 10.7194 - val_accuracy: 0.3261\n",
            "Epoch 24/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0815 - accuracy: 0.9674 - val_loss: 10.9629 - val_accuracy: 0.3261\n",
            "Epoch 25/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9565 - val_loss: 11.2251 - val_accuracy: 0.3261\n",
            "Epoch 26/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0901 - accuracy: 0.9565 - val_loss: 11.3753 - val_accuracy: 0.3261\n",
            "Epoch 27/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1298 - accuracy: 0.9402 - val_loss: 11.7904 - val_accuracy: 0.3261\n",
            "Epoch 28/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.9620 - val_loss: 13.1057 - val_accuracy: 0.3261\n",
            "Epoch 29/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0864 - accuracy: 0.9674 - val_loss: 13.1574 - val_accuracy: 0.3261\n",
            "Epoch 30/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9674 - val_loss: 13.1176 - val_accuracy: 0.3261\n",
            "Epoch 31/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9837 - val_loss: 13.2007 - val_accuracy: 0.3261\n",
            "Epoch 32/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0901 - accuracy: 0.9565 - val_loss: 13.2267 - val_accuracy: 0.3261\n",
            "Epoch 33/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9511 - val_loss: 13.5024 - val_accuracy: 0.3261\n",
            "Epoch 34/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9620 - val_loss: 13.6728 - val_accuracy: 0.3261\n",
            "Epoch 35/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0619 - accuracy: 0.9783 - val_loss: 13.9530 - val_accuracy: 0.3261\n",
            "Epoch 36/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.9728 - val_loss: 14.0659 - val_accuracy: 0.3261\n",
            "Epoch 37/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9891 - val_loss: 14.4227 - val_accuracy: 0.3261\n",
            "Epoch 38/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.9946 - val_loss: 14.5974 - val_accuracy: 0.3261\n",
            "Epoch 39/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9783 - val_loss: 14.7899 - val_accuracy: 0.3261\n",
            "Epoch 40/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9891 - val_loss: 14.7075 - val_accuracy: 0.3261\n",
            "Epoch 41/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9891 - val_loss: 14.7236 - val_accuracy: 0.3261\n",
            "Epoch 42/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9946 - val_loss: 14.6697 - val_accuracy: 0.3261\n",
            "Epoch 43/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.9946 - val_loss: 14.6574 - val_accuracy: 0.3261\n",
            "Epoch 44/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9891 - val_loss: 14.5091 - val_accuracy: 0.3261\n",
            "Epoch 45/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 14.6681 - val_accuracy: 0.3261\n",
            "Epoch 46/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0139 - accuracy: 0.9946 - val_loss: 14.6089 - val_accuracy: 0.3261\n",
            "Epoch 47/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0238 - accuracy: 0.9891 - val_loss: 14.9220 - val_accuracy: 0.3261\n",
            "Epoch 48/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 14.9676 - val_accuracy: 0.3261\n",
            "Epoch 49/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 14.9707 - val_accuracy: 0.3261\n",
            "Epoch 50/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 14.9749 - val_accuracy: 0.3261\n",
            "Epoch 51/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 15.0278 - val_accuracy: 0.3261\n",
            "Epoch 52/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 6.5294e-04 - accuracy: 1.0000 - val_loss: 15.1979 - val_accuracy: 0.3261\n",
            "Epoch 53/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 15.3494 - val_accuracy: 0.3261\n",
            "Epoch 54/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 6.5936e-04 - accuracy: 1.0000 - val_loss: 15.4071 - val_accuracy: 0.3261\n",
            "Epoch 55/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 2.2177e-04 - accuracy: 1.0000 - val_loss: 15.4815 - val_accuracy: 0.3261\n",
            "Epoch 56/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 2.4819e-04 - accuracy: 1.0000 - val_loss: 15.5247 - val_accuracy: 0.3261\n",
            "Epoch 57/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 2.3211e-04 - accuracy: 1.0000 - val_loss: 15.5835 - val_accuracy: 0.3261\n",
            "Epoch 58/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 1.1878e-04 - accuracy: 1.0000 - val_loss: 15.6188 - val_accuracy: 0.3261\n",
            "Epoch 59/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 1.2757e-04 - accuracy: 1.0000 - val_loss: 15.6375 - val_accuracy: 0.3261\n",
            "Epoch 60/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 1.1366e-04 - accuracy: 1.0000 - val_loss: 15.6519 - val_accuracy: 0.3261\n",
            "Epoch 61/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 9.8605e-05 - accuracy: 1.0000 - val_loss: 15.6994 - val_accuracy: 0.3261\n",
            "Epoch 62/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 7.5940e-05 - accuracy: 1.0000 - val_loss: 15.7655 - val_accuracy: 0.3261\n",
            "Epoch 63/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 9.1776e-05 - accuracy: 1.0000 - val_loss: 15.8814 - val_accuracy: 0.3261\n",
            "Epoch 64/70\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 1.6646e-04 - accuracy: 1.0000 - val_loss: 15.9686 - val_accuracy: 0.3261\n",
            "Epoch 65/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 3.8950e-05 - accuracy: 1.0000 - val_loss: 16.0367 - val_accuracy: 0.3261\n",
            "Epoch 66/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 4.8531e-05 - accuracy: 1.0000 - val_loss: 16.0836 - val_accuracy: 0.3261\n",
            "Epoch 67/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 2.6735e-05 - accuracy: 1.0000 - val_loss: 16.1161 - val_accuracy: 0.3261\n",
            "Epoch 68/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 2.5488e-05 - accuracy: 1.0000 - val_loss: 16.1304 - val_accuracy: 0.3261\n",
            "Epoch 69/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 3.4845e-05 - accuracy: 1.0000 - val_loss: 16.1247 - val_accuracy: 0.3261\n",
            "Epoch 70/70\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 3.4647e-05 - accuracy: 1.0000 - val_loss: 16.1114 - val_accuracy: 0.3261\n",
            "Test loss: 16.111374316008195\n",
            "Test accuracy: 0.32608696818351746\n",
            "predict: [3 3 4 4 5 5 5 5 5 5 5 5 5 4 4 4 4 2 0 0]\n",
            "Real:    [3 3 4 4 5 5 5 6 6 6 5 5 5 4 4 4 4 2 0 0]\n",
            "Accuracy(%): 85.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}